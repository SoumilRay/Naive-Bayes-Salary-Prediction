{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1f4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings('ignore')\n",
    "df=pd.read_csv(r\"adult_edited.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ac6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 1\n",
    "df = df[df['workclass'] != ' ?']\n",
    "df = df[df['native-country'] != ' ?']\n",
    "df_train = df.sample(frac=0.67,random_state=42)\n",
    "df_test = df.drop(df_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2307702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4551\n",
      "1513\n",
      "Prior probability of <=50K is  0.7504947229551451\n",
      "Prior probability of >50K is  0.2495052770448549\n"
     ]
    }
   ],
   "source": [
    "#TASK 2\n",
    "\n",
    "#Calculating prior probabilities\n",
    "df_train_temp = df_train.apply(lambda x : True\n",
    "            if x['target'] == \" <=50K\" else False, axis = 1)\n",
    "num_less = len(df_train_temp[df_train_temp == True].index)\n",
    "print(num_less)\n",
    "\n",
    "df_train_temp = df_train.apply(lambda x : True\n",
    "            if x['target'] == \" >50K\" else False, axis = 1)\n",
    "num_grea = len(df_train_temp[df_train_temp == True].index)\n",
    "print(num_grea)\n",
    "\n",
    "total = num_less+num_grea\n",
    "ppl=num_less/total\n",
    "ppg=num_grea/total\n",
    "print('Prior probability of <=50K is ',ppl)\n",
    "print('Prior probability of >50K is ',ppg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63616cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating conditional probabilities of features wrt target\n",
    "\n",
    "#number of rows that contain arg1\n",
    "def count_inst_1(arg1): #as this is only for target column, we don't need to worry about wrong column being selected\n",
    "    for col in df_train.columns:\n",
    "        if arg1 in df_train[col].values:\n",
    "            return df_train[col].value_counts()[arg1]\n",
    "# print(count_instances(' Bachelors'))  not matching ctrl+f of vs code for some reason\n",
    "\n",
    "#returns the column that contains arg\n",
    "def whichCol(index):\n",
    "    if index==0:\n",
    "        return 'age'\n",
    "    if index==1:\n",
    "        return 'workclass'\n",
    "    if index==2:\n",
    "        return 'fnlwgt'\n",
    "    if index==3:\n",
    "        return 'education'\n",
    "    if index==4:\n",
    "        return 'education-num'\n",
    "    if index==5:\n",
    "        return 'marital-status'\n",
    "    if index==6:\n",
    "        return 'occupation'\n",
    "    if index==7:\n",
    "        return 'relationship'\n",
    "    if index==8:\n",
    "        return 'race'\n",
    "    if index==9:\n",
    "        return 'sex'\n",
    "    if index==10:\n",
    "        return 'capital-gain'\n",
    "    if index==11:\n",
    "        return 'capital-loss'\n",
    "    if index==12:\n",
    "        return 'house-per-week'\n",
    "    if index==13:\n",
    "        return 'native-country'\n",
    "    if index==14:\n",
    "        return 'target'\n",
    "\n",
    "#number of rows that contain both arg1 and arg2\n",
    "def count_inst_2(arg1, arg2,f_index):\n",
    "    col1 = whichCol(f_index)\n",
    "    col2 = whichCol(14)\n",
    "    mask = (df_train[col1].str.contains(arg1)) & (df_train[col2].str.contains(arg2))\n",
    "    return len(df_train[mask])\n",
    "\n",
    "#returns conditional probability if the feature is discrete\n",
    "def condProb_disc(feature,target,f_index):\n",
    "    x1 = count_inst_2(feature,target,f_index)\n",
    "    x2 = count_inst_1(target)\n",
    "    \n",
    "    return ((x1+1)/(x2+14)) #laplace smoothing applied\n",
    "\n",
    "def count_normal(feature, target,f_index):\n",
    "    col1 = whichCol(f_index)\n",
    "    col2 = 'target'\n",
    "    #mask = df_train.query(\"@col2 == @target\")\n",
    "    mask = df_train.loc[df_train[col2] == target]\n",
    "    mu = mask[col1].mean()\n",
    "    sigma = mask[col1].std()\n",
    "    return mu, sigma\n",
    "    \n",
    "\n",
    "#returns conditional probability if the feature is continuous\n",
    "def condProb_cont(feature,target,f_index):\n",
    "    mu, sigma = count_normal(feature, target,f_index)\n",
    "    normdistprob = (1/(math.sqrt(2*math.pi)*sigma))*math.exp(-(feature - mu)**2/(2*sigma**2))\n",
    "#     if(normdistprb == 0):\n",
    "#         normdistprob = 0.001 #smoothing tactic\n",
    "    return normdistprob\n",
    "    \n",
    "    \n",
    "\n",
    "#returns conditional probability\n",
    "def condProb(feature,target,f_index):\n",
    "    str=whichCol(f_index)\n",
    "    #print(str)\n",
    "    if str=='age':\n",
    "        return condProb_cont(feature,target,f_index)\n",
    "    if str=='fnlwgt':\n",
    "        return condProb_cont(feature,target,f_index)\n",
    "    if str=='education-num':\n",
    "        return condProb_cont(feature,target,f_index)\n",
    "    if str=='capital-gain':\n",
    "        return condProb_cont(feature,target,f_index)\n",
    "    if str=='capital-loss':\n",
    "        return condProb_cont(feature,target,f_index)\n",
    "    if str=='house-per-week':\n",
    "        return condProb_cont(feature,target,f_index)\n",
    "    return condProb_disc(feature,target,f_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f46660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFinalProb(arg1,arg2,arg3,arg4,arg5,arg6,arg7,arg8,arg9,arg10,arg11,arg12,arg13,arg14, target):\n",
    "    bigterml= condProb(arg1,' <=50K',0)*condProb(arg2,' <=50K',1)*condProb(arg3,' <=50K',2)*condProb(arg4,' <=50K',3)*condProb(arg5,' <=50K',4)*condProb(arg6,' <=50K',5)*condProb(arg7,' <=50K',6)*condProb(arg8,' <=50K',7)*condProb(arg9,' <=50K',8)*condProb(arg10,' <=50K',9)*condProb(arg11,' <=50K',10)*condProb(arg12,' <=50K',11)*condProb(arg13,' <=50K',12)*condProb(arg14,' <=50K',13)\n",
    "    bigtermg= condProb(arg1,' >50K',0)*condProb(arg2,' >50K',1)*condProb(arg3,' >50K',2)*condProb(arg4,' >50K',3)*condProb(arg5,' >50K',4)*condProb(arg6,' >50K',5)*condProb(arg7,' >50K',6)*condProb(arg8,' >50K',7)*condProb(arg9,' >50K',8)*condProb(arg10,' >50K',9)*condProb(arg11,' >50K',10)*condProb(arg12,' >50K',11)*condProb(arg13,' >50K',12)*condProb(arg14,' >50K',13)\n",
    "    if target==' <=50K':\n",
    "        return (ppl*bigterml)/((ppl*bigterml)+(ppg*bigtermg))\n",
    "    if target==' >50K':\n",
    "        return (ppg*bigtermg)/((ppl*bigterml)+(ppg*bigtermg))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfb8c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <=50K\n"
     ]
    }
   ],
   "source": [
    "def classify(arg1,arg2,arg3,arg4,arg5,arg6,arg7,arg8,arg9,arg10,arg11,arg12,arg13,arg14):\n",
    "    a=calcFinalProb(arg1,arg2,arg3,arg4,arg5,arg6,arg7,arg8,arg9,arg10,arg11,arg12,arg13,arg14,' <=50K')\n",
    "    b=calcFinalProb(arg1,arg2,arg3,arg4,arg5,arg6,arg7,arg8,arg9,arg10,arg11,arg12,arg13,arg14,' >50K')\n",
    "    if(a>b):\n",
    "        return ' <=50K'\n",
    "    else:\n",
    "        return ' >50K'\n",
    "print (classify(53, ' Private', 234721, ' 11th', 7, ' Married-civ-spouse', ' Handlers-cleaners', ' Husband', ' Black', ' Male', 0, 0, 40, ' United-States'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7809e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest_y = df_test['target']\n",
    "df2 = df_test.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "030c7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NOW WE WANT TO TEST THE ACCURACY USING DF_TEST\n",
    "# #There are 9953 rows in df_test\n",
    "# correct=0\n",
    "# for i in range (9953):\n",
    "#     str = classify(df_test.iat[i,0],df_test.iat[i,1],df_test.iat[i,2],df_test.iat[i,3],df_test.iat[i,4],df_test.iat[i,5],df_test.iat[i,6],df_test.iat[i,7],df_test.iat[i,8],df_test.iat[i,9],df_test.iat[i,10],df_test.iat[i,11],df_test.iat[i,12],df_test.iat[i,13],df_test.iat[i,14])\n",
    "#     if str==df_test.iat[i,14]:\n",
    "#         correct=correct+1\n",
    "# print('accuracy: ')\n",
    "# print(correct/9953)\n",
    "# #taking too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de478e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8302644794107801\n",
      "Precision: 0.8302644794107801\n",
      "Recall 1.0\n",
      "F1 score 0.9072617523321749\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dataframe to store the results\n",
    "result_df = pd.DataFrame(columns=['predicted'])\n",
    "\n",
    "# Initialize the correct counter\n",
    "correct = 0\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "#we shall consider >50K as positive and <= 50K as negative\n",
    "\n",
    "# Iterate over each row of the dataframe using itertuples\n",
    "for row in df2.itertuples(index=False):\n",
    "    age, workclass, fnlwgt, education, education_num, marital_status, occupation, \\\n",
    "    relationship, race, sex, capital_gain, capital_loss, hours_per_week, native_country = row\n",
    "    \n",
    "    # call classify() function with the row values\n",
    "    result = classify(age, workclass, fnlwgt, education, education_num, marital_status, \n",
    "                      occupation, relationship, race, sex, capital_gain, capital_loss, \n",
    "                      hours_per_week, native_country)\n",
    "    #print(result)\n",
    "    # Add the result to the result_df\n",
    "    result_df = result_df.append({'predicted': result}, ignore_index=True)\n",
    "\n",
    "# Compare the result_df with the dftest_y dataframe\n",
    "# for index, row in df_test['target'].iteritems():\n",
    "#     if row == (result_df.loc[index]):\n",
    "#         correct += 1\n",
    "   \n",
    "result_df = result_df.to_numpy()\n",
    "actual_df = df_test['target'].to_numpy()\n",
    "\n",
    "for i in range (len(result_df)):\n",
    "    if result_df[i] == actual_df[i]:\n",
    "        correct += 1\n",
    "        if result_df[i] == ' <50k':\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    else:\n",
    "        if result_df[i] == ' <50k':\n",
    "            fn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "\n",
    "\n",
    "#Calculate the accuracy\n",
    "accuracy = correct / len(result_df)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1 = tp/(tp + 1/2*(fp+fn))\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall\", recall)\n",
    "print(\"F1 score\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
